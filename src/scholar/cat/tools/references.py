from typing import Any, Dict, List
import datetime

import elasticsearch
import fatcat_openapi_client as fcapi
from elasticsearch_dsl import Search
from fatcat_openapi_client import ReleaseEntity
from pydantic import BaseModel, validator

from scholar.cat.tools.transforms.access import (
        AccessOption,
        release_access_options,
)
from scholar.cat.tools.transforms.entities import entity_to_dict


class BiblioRef(BaseModel):
    """bibliographic reference"""

    # ("release", source_release_ident, ref_index)
    # ("wikipedia", source_wikipedia_article, ref_index)
    _key: str|None
    update_ts: datetime.datetime|None

    # metadata about source of reference
    source_release_ident: str|None
    source_work_ident: str|None
    # with lang prefix like "en:Superglue"
    source_wikipedia_article: str|None
    source_release_stage: str|None
    source_year: int|None

    # context of the reference itself
    # 1-indexed, not 0-indexed
    ref_index: int|None  # TODO: actually optional?
    # eg, "Lee86", "BIB23"
    ref_key: str|None
    # eg, page number
    ref_locator: str|None

    # target of reference (identifiers)
    target_release_ident: str|None
    target_work_ident: str|None
    target_openlibrary_work: str|None
    # TODO: target_url_surt: str|None
    # would not be stored in elasticsearch, but would be auto-generated by all "get" methods from the SURT, so calling code does not need to do SURT transform
    target_url: str|None

    # crossref, pubmed, grobid, etc
    match_provenance: str|None
    # strong, weak, etc
    match_status: str|None
    # TODO: "match_strength"?
    # "doi", "isbn", "fuzzy title, author", etc
    # maybe "fuzzy-title-author"?
    match_reason: str|None

    # only if no release_ident link/match
    target_unstructured: str|None
    target_csl: Dict[str, Any]|None

    def hacks(self) -> "BiblioRef":
        """
        Temporary (?) hacks to work around schema/data issues
        """
        if self.target_openlibrary_work and self.target_openlibrary_work.startswith("/works/"):
            self.target_openlibrary_work = self.target_openlibrary_work[7:]

        # work-arounds for bad/weird ref_key
        if self.ref_key:
            self.ref_key = self.ref_key.strip()
            if self.ref_key[0] in ["/", "_"]:
                self.ref_key = self.ref_key[1:]
            if (
                self.ref_key.startswith("10.")
                and "SICI" in self.ref_key
                and "-" in self.ref_key
            ):
                self.ref_key = self.ref_key.split("-")[-1]
            if self.ref_key.startswith("10.") and "_" in self.ref_key:
                self.ref_key = self.ref_key.split("_")[-1]
            if len(self.ref_key) > 10 and "#" in self.ref_key:
                self.ref_key = self.ref_key.split("#")[-1]
            if len(self.ref_key) > 10 and "_" in self.ref_key:
                self.ref_key = self.ref_key.split("_")[-1]
        if not self.ref_key and self.ref_index is not None:
            self.ref_key = str(self.ref_index)
        return self


class EnrichedBiblioRef(BaseModel):
    # enriched version of BiblioRef with complete ReleaseEntity object as
    # fetched from the fatcat API. CSL-JSON metadata would be derived from
    # the full release entity.
    ref: BiblioRef
    release: ReleaseEntity|None
    # TODO: openlibrary work?
    access: List[AccessOption]

    @validator("release")
    @classmethod
    def check_release(cls: Any, v: ReleaseEntity) -> ReleaseEntity:
        if v is not None and not isinstance(v, ReleaseEntity):
            raise ValueError("expected a ReleaseEntity")
        return v

    class Config:
        arbitrary_types_allowed = True
        json_encoders = {
            ReleaseEntity: entity_to_dict,
        }


class RefHits(BaseModel):
    count_returned: int
    count_total: int
    offset: int
    limit: int
    query_time_ms: int
    query_wall_time_ms: int
    result_refs: List[BiblioRef]

    class Config:
        json_encoders = {
            ReleaseEntity: entity_to_dict,
        }

    def as_enriched(self, enriched_refs: List[EnrichedBiblioRef]) -> "RefHitsEnriched":
        return RefHitsEnriched(
            count_returned=self.count_returned,
            count_total=self.count_total,
            offset=self.offset,
            limit=self.limit,
            query_time_ms=self.query_time_ms,
            query_wall_time_ms=self.query_wall_time_ms,
            result_refs=enriched_refs,
        )



class RefHitsEnriched(BaseModel):
    count_returned: int
    count_total: int
    offset: int
    limit: int
    query_time_ms: int
    query_wall_time_ms: int
    result_refs: List[EnrichedBiblioRef]

    class Config:
        json_encoders = {
            ReleaseEntity: entity_to_dict,
        }

def get_inbound_refs(
    es_client:         Any,
    release_ident:     str|None = None,
    work_ident:        str|None = None,
    openlibrary_work:  str|None = None,
    url:               str|None = None,
    consolidate_works: bool = False,
    filter_stage:      List[str] = [],
    sort:              str|None = None,
    limit:             int = 25,
    offset:            int|None = None,
    es_index:          str = "fatcat_ref",
) -> RefHits:

    search = Search(using=es_client, index=es_index)

    if consolidate_works:
        search = search.extra(
            collapse={
                "field": "source_work_ident",
                "inner_hits": {
                    "name": "source_more",
                    "size": 0,
                },
            }
        )

    if release_ident:
        search = search.filter("term", target_release_ident=release_ident)
    elif work_ident:
        search = search.filter("term", target_work_ident=work_ident)
    elif openlibrary_work:
        search = search.filter("term", target_openlibrary_work=openlibrary_work)
    else:
        raise ValueError("require a lookup key")

    if filter_stage:
        search = search.filter("term", source_stage=filter_stage)

    if sort == "newest":
        search = search.sort("-source_year")
    elif sort == "oldest":
        search = search.sort("source_year")
    else:
        search = search.sort("-source_year")

    return _execute_ref_query(search, limit=limit, offset=offset)

def _execute_ref_query(search: Any,
                       limit:  int,
                       offset: int|None = None,
) -> RefHits:
    """
    Internal helper for querying elasticsearch refs index and transforming hits
    """

    limit = min(limit, 200)
    if not offset or offset < 0:
        offset = 0

    search = search.params(track_total_hits=True)
    search = search[offset : (offset + limit)]

    query_start = datetime.datetime.now()
    try:
        resp = search.execute()
    except elasticsearch.exceptions.RequestError as e_raw:
        # this is a "user" error
        e: Any = e_raw
        # logging.warn("elasticsearch 400: " + str(e.info))
        if e.info.get("error", {}).get("root_cause", {}):
            raise ValueError(str(e.info["error"]["root_cause"][0].get("reason"))) from e
        else:
            raise ValueError(str(e.info)) from e
    except elasticsearch.exceptions.TransportError as e:
        # all other errors
        # logging.warn(f"elasticsearch non-200 status code: {e.info}")
        raise IOError(str(e.info)) from e
    query_delta = datetime.datetime.now() - query_start

    result_refs = []
    for h in resp.hits:
        # might be a list because of consolidation
        if isinstance(h._d_.get("source_work_ident"), list):
            h._d_["source_work_ident"] = h._d_["source_work_ident"][0]
        result_refs.append(BiblioRef.parse_obj(h._d_).hacks())

    return RefHits(
        count_returned=len(result_refs),
        # ES 7.x style "total"
        count_total=resp.hits.total.value,
        offset=offset,
        limit=limit,
        query_time_ms=int(resp.took),
        query_wall_time_ms=int(query_delta.total_seconds() * 1000),
        result_refs=result_refs,
    )

# run fatcat API fetches for each ref and return "enriched" refs
def enrich_inbound_refs(
    refs:     List[BiblioRef],
    fcclient: fcapi.DefaultApi,
    hide:     str|None = "refs",
    expand:   str|None = "container,files,webcaptures,filesets",
) -> List[EnrichedBiblioRef]:
    enriched = []
    for ref in refs:
        release = None
        access = []
        if ref.source_release_ident:
            release = fcclient.get_release(
                ref.source_release_ident, hide=hide, expand=expand
            )
            access = release_access_options(release)
        if ref.source_wikipedia_article:
            wiki_lang = ref.source_wikipedia_article.split(":")[0]
            wiki_article = ":".join(ref.source_wikipedia_article.split(":")[1:]).replace(
                " ", "_"
            )
            access.append(
                AccessOption(
                    access_type="wikipedia",
                    access_url=f"https://{wiki_lang}.wikipedia.org/wiki/{wiki_article}",
                    mimetype=None,
                    size_bytes=None,
                    thumbnail_url=None,
                )
            )
        enriched.append(
            EnrichedBiblioRef(
                ref=ref,
                access=access,
                release=release,
            )
        )
    return enriched

def get_outbound_refs(
    es_client:         Any,
    release_ident:     str|None = None,
    work_ident:        str|None = None,
    wikipedia_article: str|None = None,
    limit:             int = 100,
    offset:            int|None = None,
    es_index:          str = "fatcat_ref",
) -> RefHits:

    search = Search(using=es_client, index=es_index)

    if release_ident:
        search = search.filter("term", source_release_ident=release_ident)
    elif work_ident:
        search = search.filter("term", source_work_ident=work_ident)
    elif wikipedia_article:
        search = search.filter("term", source_wikipedia_article=wikipedia_article)
    else:
        raise ValueError("require a lookup key")

    search = search.sort("ref_index")

    # re-sort by index
    hits = _execute_ref_query(search, limit=limit, offset=offset)
    hits.result_refs = sorted(hits.result_refs, key=lambda r: r.ref_index or 0)
    return hits

def enrich_outbound_refs(
    refs: List[BiblioRef],
    fcclient: fcapi.DefaultApi,
    hide: str|None = "refs",
    expand: str|None = "container,files,webcaptures,filesets",
) -> List[EnrichedBiblioRef]:
    enriched = []
    for ref in refs:
        release = None
        access = []
        if ref.target_release_ident:
            release = fcclient.get_release(
                ref.target_release_ident, hide=hide, expand=expand
            )
            access = release_access_options(release)
        if ref.target_openlibrary_work:
            access.append(
                AccessOption(
                    access_type="openlibrary",
                    access_url=f"https://openlibrary.org/works/{ref.target_openlibrary_work}",
                    mimetype=None,
                    size_bytes=None,
                    thumbnail_url=None,
                )
            )
        if ref.target_url and "://web.archive.org/" in ref.target_url:
            access.append(
                AccessOption(
                    access_type="wayback",
                    access_url=ref.target_url,
                    mimetype=None,
                    size_bytes=None,
                    thumbnail_url=None,
                )
            )
        enriched.append(
            EnrichedBiblioRef(
                ref=ref,
                access=access,
                release=release,
            )
        )
    return enriched

